<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AllSenses AI Agent - Audio Mode Demo</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
        }

        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 40px;
            max-width: 800px;
            width: 90%;
            text-align: center;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        .header {
            margin-bottom: 30px;
        }

        .title {
            font-size: 2.5rem;
            font-weight: bold;
            margin-bottom: 10px;
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
            margin-bottom: 20px;
        }

        .aws-badge {
            display: inline-block;
            background: #ff9500;
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: bold;
            margin-bottom: 30px;
        }

        .demo-section {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 30px;
            margin: 20px 0;
        }

        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(45deg, #ff6b6b, #ee5a24);
            color: white;
            font-size: 3rem;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 20px;
            box-shadow: 0 8px 25px rgba(238, 90, 36, 0.4);
        }

        .mic-button:hover {
            transform: scale(1.1);
            box-shadow: 0 12px 35px rgba(238, 90, 36, 0.6);
        }

        .mic-button.listening {
            background: linear-gradient(45deg, #00d2ff, #3a7bd5);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }

        .status-display {
            margin: 20px 0;
            padding: 20px;
            border-radius: 10px;
            font-size: 1.1rem;
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .status-safe {
            background: rgba(46, 204, 113, 0.2);
            border: 2px solid #2ecc71;
            color: #2ecc71;
        }

        .status-emergency {
            background: rgba(231, 76, 60, 0.2);
            border: 2px solid #e74c3c;
            color: #e74c3c;
            animation: blink 1s infinite;
        }

        .status-processing {
            background: rgba(52, 152, 219, 0.2);
            border: 2px solid #3498db;
            color: #3498db;
        }

        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0.5; }
        }

        .transcript {
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
            font-style: italic;
            min-height: 50px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .quick-test {
            margin-top: 30px;
        }

        .test-button {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 25px;
            font-size: 1rem;
            cursor: pointer;
            margin: 10px;
            transition: all 0.3s ease;
        }

        .test-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);
        }

        .aws-services {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }

        .service-badge {
            background: rgba(255, 255, 255, 0.1);
            padding: 10px;
            border-radius: 10px;
            font-size: 0.9rem;
        }

        .live-url {
            background: rgba(0, 0, 0, 0.3);
            padding: 15px;
            border-radius: 10px;
            font-family: monospace;
            font-size: 0.9rem;
            word-break: break-all;
            margin: 20px 0;
        }

        .instructions {
            text-align: left;
            background: rgba(255, 255, 255, 0.05);
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }

        .instructions h3 {
            color: #4ecdc4;
            margin-bottom: 10px;
        }

        .instructions ul {
            padding-left: 20px;
        }

        .instructions li {
            margin: 8px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="title">üé§ AllSenses AI Agent</h1>
            <p class="subtitle">AWS Bedrock-Powered Audio Threat Detection</p>
            <div class="aws-badge">AWS Hackathon MVP - AI Agent Qualified</div>
        </div>

        <div class="demo-section">
            <h2>üéôÔ∏è Audio Mode Demo</h2>
            <p>Click the microphone to start voice monitoring</p>
            
            <button id="micButton" class="mic-button" onclick="toggleListening()">
                üé§
            </button>

            <div id="statusDisplay" class="status-display status-safe">
                üü¢ Ready for voice input - Click microphone to start
            </div>

            <div id="transcript" class="transcript">
                Transcript will appear here...
            </div>

            <div class="aws-services">
                <div class="service-badge">ü§ñ AWS Bedrock<br>Claude-3-Haiku</div>
                <div class="service-badge">‚ö° AWS Lambda<br>AI Processing</div>
                <div class="service-badge">üíæ DynamoDB<br>Assessment Storage</div>
                <div class="service-badge">üìß Amazon SNS<br>Emergency Alerts</div>
                <div class="service-badge">üîê AWS IAM<br>Security</div>
            </div>
        </div>

        <div class="demo-section">
            <h3>üöÄ Live AI Agent Endpoint</h3>
            <div class="live-url" id="liveUrl">
                https://xphq336pp7payd7wycrjyokayy0vqwjz.lambda-url.us-east-1.on.aws/
            </div>
        </div>

        <div class="quick-test">
            <h3>‚ö° Quick Demo for Judges</h3>
            <button class="test-button" onclick="testEmergency()">üö® Test Emergency</button>
            <button class="test-button" onclick="testNormal()">‚úÖ Test Normal</button>
            <button class="test-button" onclick="testAudio()">üéµ Test Audio Mode</button>
        </div>

        <div class="instructions">
            <h3>üìã Demo Instructions</h3>
            <ul>
                <li><strong>Voice Demo:</strong> Click microphone and say "Help! Emergency!" to trigger AI analysis</li>
                <li><strong>AI Processing:</strong> AWS Bedrock Claude-3-Haiku analyzes your speech for threats</li>
                <li><strong>Autonomous Response:</strong> Emergency alerts sent automatically via SNS</li>
                <li><strong>Real-time:</strong> All processing happens in under 1 second</li>
                <li><strong>Architecture:</strong> Browser ‚Üí Speech API ‚Üí Lambda ‚Üí Bedrock ‚Üí SNS ‚Üí Email</li>
            </ul>
        </div>
    </div>

    <script>
        // AllSenses AI Agent Configuration
        const AI_AGENT_URL = 'https://xphq336pp7payd7wycrjyokayy0vqwjz.lambda-url.us-east-1.on.aws/';
        
        let isListening = false;
        let recognition = null;

        // Initialize Speech Recognition
        function initializeSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = 'en-US';

                recognition.onstart = function() {
                    console.log('Speech recognition started');
                    updateStatus('üéôÔ∏è Listening... Speak now!', 'processing');
                };

                recognition.onresult = function(event) {
                    let finalTranscript = '';
                    let interimTranscript = '';

                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        const transcript = event.results[i][0].transcript;
                        if (event.results[i].isFinal) {
                            finalTranscript += transcript;
                        } else {
                            interimTranscript += transcript;
                        }
                    }

                    // Update transcript display
                    document.getElementById('transcript').textContent = 
                        finalTranscript || interimTranscript || 'Listening...';

                    // Process final transcript
                    if (finalTranscript) {
                        processAudioInput(finalTranscript.trim());
                    }
                };

                recognition.onerror = function(event) {
                    console.error('Speech recognition error:', event.error);
                    updateStatus('‚ùå Speech recognition error. Try again.', 'emergency');
                    stopListening();
                };

                recognition.onend = function() {
                    console.log('Speech recognition ended');
                    if (isListening) {
                        // Restart if still supposed to be listening
                        setTimeout(() => {
                            if (isListening) {
                                recognition.start();
                            }
                        }, 100);
                    }
                };
            } else {
                alert('Speech recognition not supported in this browser. Please use Chrome.');
            }
        }

        // Toggle listening state
        function toggleListening() {
            if (!recognition) {
                initializeSpeechRecognition();
            }

            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        }

        function startListening() {
            isListening = true;
            const micButton = document.getElementById('micButton');
            micButton.classList.add('listening');
            micButton.textContent = 'üî¥';
            
            try {
                recognition.start();
            } catch (error) {
                console.error('Error starting recognition:', error);
                stopListening();
            }
        }

        function stopListening() {
            isListening = false;
            const micButton = document.getElementById('micButton');
            micButton.classList.remove('listening');
            micButton.textContent = 'üé§';
            
            if (recognition) {
                recognition.stop();
            }
            
            updateStatus('üü¢ Ready for voice input - Click microphone to start', 'safe');
        }

        // Process audio input through AI Agent
        async function processAudioInput(transcript) {
            updateStatus('ü§ñ AI Agent analyzing with AWS Bedrock...', 'processing');
            
            const payload = {
                message: transcript,
                userId: 'hackathon-demo',
                audioData: transcript,
                location: {
                    lat: 40.7128,
                    lng: -74.0060,
                    address: 'Hackathon Demo Location'
                },
                deviceId: 'audio-demo-device'
            };

            try {
                const response = await fetch(AI_AGENT_URL, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();
                console.log('AI Agent Response:', result);

                // Display results
                displayAIResponse(result, transcript);

            } catch (error) {
                console.error('Error calling AI Agent:', error);
                updateStatus('‚ùå Error connecting to AI Agent', 'emergency');
            }
        }

        // Display AI response
        function displayAIResponse(result, originalTranscript) {
            const threatLevel = result.threatLevel || 'UNKNOWN';
            const confidence = result.confidence || 0;
            const emergencyTriggered = result.emergencyTriggered || false;
            const reasoning = result.reasoning || 'No reasoning provided';

            // Update transcript with AI analysis
            document.getElementById('transcript').innerHTML = `
                <strong>You said:</strong> "${originalTranscript}"<br>
                <strong>AI Analysis:</strong> ${reasoning}<br>
                <strong>Threat Level:</strong> ${threatLevel} (${Math.round(confidence * 100)}% confidence)
            `;

            // Update status based on results
            if (emergencyTriggered) {
                updateStatus(`üö® EMERGENCY DETECTED! Alert sent via SNS`, 'emergency');
                
                // Show emergency response details
                if (result.emergencyResponse) {
                    setTimeout(() => {
                        updateStatus(`‚úÖ Emergency alert sent! Message ID: ${result.emergencyResponse.messageId}`, 'emergency');
                    }, 2000);
                }
            } else {
                updateStatus(`‚úÖ ${threatLevel} threat level - No emergency detected`, 'safe');
            }

            // Auto-restart listening after 3 seconds
            setTimeout(() => {
                if (isListening) {
                    updateStatus('üéôÔ∏è Listening... Speak now!', 'processing');
                }
            }, 3000);
        }

        // Update status display
        function updateStatus(message, type) {
            const statusDisplay = document.getElementById('statusDisplay');
            statusDisplay.textContent = message;
            statusDisplay.className = `status-display status-${type}`;
        }

        // Quick test functions
        async function testEmergency() {
            updateStatus('üß™ Testing emergency scenario...', 'processing');
            await processAudioInput('HELP! There is an emergency situation here!');
        }

        async function testNormal() {
            updateStatus('üß™ Testing normal scenario...', 'processing');
            await processAudioInput('AllSenses AI Agent demo for hackathon judges');
        }

        async function testAudio() {
            updateStatus('üß™ Testing audio processing...', 'processing');
            await processAudioInput('I feel unsafe and need assistance');
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', function() {
            console.log('AllSenses AI Agent Audio Demo Ready');
            console.log('AI Agent URL:', AI_AGENT_URL);
            
            // Initialize speech recognition
            initializeSpeechRecognition();
            
            // Update live URL display
            document.getElementById('liveUrl').textContent = AI_AGENT_URL;
        });

        // Handle page visibility changes
        document.addEventListener('visibilitychange', function() {
            if (document.hidden && isListening) {
                stopListening();
            }
        });
    </script>
</body>
</html>